name: Agent Evaluation

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  eval:
    runs-on: ubuntu-latest

    env:
      # Safe defaults for CI
      ENABLE_CONFLUENCE: "false"
      MCP_SERVER_URL: "http://localhost:8082/mcp"
      LANGGRAPH_SERVER_URL: "http://localhost:2024"
      LANGGRAPH_GRAPH_NAME: "data_analysis_agent"
      # Force deterministic behaviour as much as possible
      CHAT_NODE__temperature: "0"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up uv and Python
        uses: astral-sh/setup-uv@v3
        with:
          python-version: "3.12"

      - name: Sync dependencies with uv (uses lockfile cache)
        run: |
          uv sync --frozen

      - name: Start MCP server
        run: |
          nohup uv run python -m src.mcp_server > mcp.log 2>&1 &

      - name: Wait for MCP server
        run: |
          uv run python scripts/wait_for_http.py "http://localhost:8082/health" --timeout 90 --interval 3

      - name: Start LangGraph server
        run: |
          nohup uv run langgraph dev --config src/langgraph_server/langgraph.json > langgraph.log 2>&1 &

      - name: Wait for LangGraph server
        run: |
          uv run python scripts/wait_for_http.py "${{ env.LANGGRAPH_SERVER_URL }}/docs" --timeout 120 --interval 3

      - name: Run evaluation
        run: |
          uv run python -m eval.run_eval --cases eval/cases --out eval_report.json --fail-under 0.5

      - name: Upload evaluation artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: eval-artifacts
          path: |
            eval_report.json
            mcp.log
            langgraph.log

