"""LangGraph definition for the data analysis agent with domain-separated architecture."""

import logging
from pathlib import Path
from typing import Annotated, Literal

from dotenv import load_dotenv
from langchain_core.messages import BaseMessage
from langchain_core.tools import BaseTool
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import END, StateGraph
from langgraph.graph.message import add_messages
from typing_extensions import NotRequired, TypedDict

from .llm_utils import initialize_llm
from .mcp_tool_loader import MCPToolLoader
from .nodes import (
    AnalysisAgentNode,
    CodeAgentNode,
    ConfluenceAgentNode,
    FinalResponderNode,
    KnowledgeAgentNode,
    RouterNode,
    ToolAgentNode,
    ToolsNode,
    VerifierNode,
)
from .nodes.utils import is_tool_name
from .settings import LLMProvider, get_settings

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)

# Load .env from project root
project_root = Path(__file__).parent.parent.parent
env_file = project_root / ".env"
if env_file.exists():
    load_dotenv(env_file)
else:
    load_dotenv()


class AgentState(TypedDict):
    """State for the data analysis agent."""

    messages: Annotated[list[BaseMessage], add_messages]
    intent: NotRequired[Literal["ANALYSIS", "KNOWLEDGE", "CONFLUENCE", "OTHER"]]
    generated_code: NotRequired[str]  # Code generated by CodeAgent
    retry_count: NotRequired[int]
    verification_result: NotRequired[dict]  # Verification result from VerifierNode
    verification_retry_count: NotRequired[int]  # Number of verification retries
    query_classification: NotRequired[
        str
    ]  # Query classification (DATA_ANALYSIS, DOCUMENT_QA, BOTH)


def filter_tools_by_domain(tools: list[BaseTool], domain: str) -> list[BaseTool]:
    """Filter tools by domain with strict masking.

    Args:
        tools: All available tools
        domain: Domain name ("analysis", "knowledge", "confluence", "run_analysis", "none")

    Returns:
        Filtered list of tools for the domain
    """
    if domain == "none":
        return []

    allowed_tool_names = {
        "analysis": ["list_datasets", "get_dataset_schema"],
        "knowledge": ["list_documents", "get_term_definition", "search_knowledge"],
        "confluence": [
            "confluence_search_pages",
            "confluence_get_page",
            "confluence_create_page",
            "confluence_update_page",
        ],
        "run_analysis": ["run_analysis"],
    }

    allowed = allowed_tool_names.get(domain, [])
    filtered = [
        tool for tool in tools if any(is_tool_name(tool.name, name) for name in allowed)
    ]

    logger.info(
        f"Filtered {len(filtered)} tools for domain '{domain}': "
        f"{[tool.name for tool in filtered]}"
    )
    return filtered


async def create_agent():
    """
    Create the data analysis agent graph with domain-separated architecture.

    Architecture:
    - Router: Classifies intent (ANALYSIS, KNOWLEDGE, CONFLUENCE, OTHER)
    - AnalysisAgent: Only sees list_datasets, get_dataset_schema
    - KnowledgeAgent: Only sees knowledge tools
    - ConfluenceAgent: Only sees Confluence tools
    - CodeAgent: Generates Python code (no tools)
    - ToolAgent: Only calls run_analysis
    - FinalResponder: Generates user-facing responses (no tools)

    Returns:
        Compiled LangGraph StateGraph
    """
    settings = get_settings()
    logger.info(
        f"Creating agent with model: {settings.chat_llm.llm_model_name} "
        f"(provider: {settings.chat_llm.llm_model_provider})"
    )

    # Load MCP tools
    mcp_tool_loader = MCPToolLoader()
    all_tools = await mcp_tool_loader._load_all_servers()

    # Log loaded tools
    tool_names = [tool.name for tool in all_tools]
    logger.info("=" * 60)
    logger.info("Agent initialized with %d tools:", len(all_tools))
    for tool_name in tool_names:
        logger.info("  - %s", tool_name)
    logger.info("=" * 60)

    # Initialize coding LLM FIRST (before any JSON mode modifications)
    # CRITICAL: CodeAgent needs a clean, plain text LLM with:
    # - NO JSON mode (response_format must be removed)
    # - NO tool bindings (CodeAgent has zero tools)
    # - NO tool_choice requirement (impossible when no tools exist)
    # This prevents "refusal" outputs from open-source LLMs
    if settings.coding_llm:
        # Create a clean config without JSON mode
        coding_llm_config = settings.coding_llm.model_copy()
        # Explicitly remove response_format if present
        if "response_format" in coding_llm_config.llm_params:
            coding_llm_params = coding_llm_config.llm_params.copy()
            coding_llm_params.pop("response_format", None)
            coding_llm_config = coding_llm_config.model_copy(
                update={"llm_params": coding_llm_params}
            )
        coding_llm = initialize_llm(coding_llm_config)
        logger.info(
            "Initialized coding_llm from settings.coding_llm (JSON mode explicitly removed)"
        )
    else:
        # Use main LLM config but ensure no JSON mode
        coding_llm_config = settings.chat_llm.model_copy()
        # Explicitly remove response_format if present
        if "response_format" in coding_llm_config.llm_params:
            coding_llm_params = coding_llm_config.llm_params.copy()
            coding_llm_params.pop("response_format", None)
            coding_llm_config = coding_llm_config.model_copy(
                update={"llm_params": coding_llm_params}
            )
        coding_llm = initialize_llm(coding_llm_config)
        logger.info(
            "Initialized coding_llm from settings.chat_llm (JSON mode explicitly removed)"
        )

    # Initialize main LLM (for agents with tools and final responder)
    llm = initialize_llm(settings.chat_llm)

    # Low-temperature LLM for router only (deterministic, JSON mode)
    # Router needs JSON mode for structured intent classification
    json_temperature = min(0.2, max(0.0, settings.chat_llm.temperature))
    json_llm_config = settings.chat_llm.model_copy(
        update={"temperature": json_temperature}
    )

    # Enable JSON mode for QwenOllama (Router only)
    if settings.chat_llm.llm_model_provider == LLMProvider.QWEN_OLLAMA:
        json_llm_config = json_llm_config.model_copy(
            update={
                "llm_params": {
                    **json_llm_config.llm_params,
                    "response_format": {"type": "json_object"},
                },
            }
        )

    llm_json = initialize_llm(json_llm_config)

    # Create tool-filtered LLMs for each domain
    analysis_tools = filter_tools_by_domain(all_tools, "analysis")
    knowledge_tools = filter_tools_by_domain(all_tools, "knowledge")
    confluence_tools = filter_tools_by_domain(all_tools, "confluence")
    run_analysis_tools = filter_tools_by_domain(all_tools, "run_analysis")

    # Bind tools to LLMs with tool_choice for open-source models
    tool_choice = None
    chat_model_name_lower = settings.chat_llm.llm_model_name.lower()
    is_qwen = "qwen" in chat_model_name_lower
    is_gpt_oss = (
        "gpt-oss" in chat_model_name_lower or "gpt_oss" in chat_model_name_lower
    )

    if settings.chat_llm.llm_model_provider == LLMProvider.QWEN_OLLAMA:
        tool_choice = getattr(settings.chat_llm, "tool_choice", "auto")
    elif settings.chat_llm.llm_model_provider == LLMProvider.LOCAL and (
        is_qwen or is_gpt_oss
    ):
        tool_choice = getattr(settings.chat_llm, "tool_choice", "auto")

    # Analysis agent LLM (only analysis tools)
    if tool_choice and analysis_tools:
        analysis_llm = llm.bind_tools(analysis_tools, tool_choice=tool_choice)
    elif analysis_tools:
        analysis_llm = llm.bind_tools(analysis_tools)
    else:
        analysis_llm = llm

    # Knowledge agent LLM (only knowledge tools)
    if tool_choice and knowledge_tools:
        knowledge_llm = llm.bind_tools(knowledge_tools, tool_choice=tool_choice)
    elif knowledge_tools:
        knowledge_llm = llm.bind_tools(knowledge_tools)
    else:
        knowledge_llm = llm

    # Confluence agent LLM (only Confluence tools)
    if tool_choice and confluence_tools:
        confluence_llm = llm.bind_tools(confluence_tools, tool_choice=tool_choice)
    elif confluence_tools:
        confluence_llm = llm.bind_tools(confluence_tools)
    else:
        confluence_llm = llm

    # Tool agent LLM (only run_analysis)
    if tool_choice and run_analysis_tools:
        tool_agent_llm = coding_llm.bind_tools(run_analysis_tools, tool_choice="auto")
    elif run_analysis_tools:
        tool_agent_llm = coding_llm.bind_tools(run_analysis_tools)
    else:
        tool_agent_llm = coding_llm

    # Initialize verifier LLM (use verifier_llm if configured, otherwise use json_llm)
    if settings.verifier_llm:
        verifier_llm = initialize_llm(settings.verifier_llm)
    else:
        verifier_llm = llm_json  # Use JSON LLM for structured verification output

    # Create node instances
    router_node = RouterNode(llm_json)
    analysis_agent_node = AnalysisAgentNode(analysis_llm)
    knowledge_agent_node = KnowledgeAgentNode(knowledge_llm)
    confluence_agent_node = ConfluenceAgentNode(confluence_llm)
    code_agent_node = CodeAgentNode(coding_llm)
    tool_agent_node = ToolAgentNode(tool_agent_llm)
    final_responder_node = FinalResponderNode(llm)
    verifier_node = VerifierNode(verifier_llm)
    tools_node = ToolsNode(all_tools)  # Tools node executes all tools

    # Create the graph
    workflow = StateGraph(AgentState)

    # Add nodes
    workflow.add_node("router", router_node)
    workflow.add_node("analysis_agent", analysis_agent_node)
    workflow.add_node("knowledge_agent", knowledge_agent_node)
    workflow.add_node("confluence_agent", confluence_agent_node)
    workflow.add_node("code_agent", code_agent_node)
    workflow.add_node("tool_agent", tool_agent_node)
    workflow.add_node("tools", tools_node)
    workflow.add_node("final_responder", final_responder_node)
    workflow.add_node("verifier", verifier_node)

    # Set entry point
    workflow.set_entry_point("router")

    # Router routing
    def route_from_router(state: AgentState) -> str:
        """Route from router based on intent."""
        intent = state.get("intent", "ANALYSIS")
        logger.info(f"Routing from router to: {intent}")
        return intent.lower()

    workflow.add_conditional_edges(
        "router",
        route_from_router,
        {
            "analysis": "analysis_agent",
            "knowledge": "knowledge_agent",
            "confluence": "confluence_agent",
            "other": "final_responder",
        },
    )

    # Analysis agent routing
    def route_from_analysis_agent(state: AgentState) -> str:
        """Route from analysis agent."""
        messages = state["messages"]
        last_message = messages[-1] if messages else None

        # Check if code generation is needed
        if (
            last_message
            and hasattr(last_message, "content")
            and isinstance(last_message.content, str)
            and "CODE_GENERATION_NEEDED" in last_message.content
        ):
            logger.info("Routing to code_agent")
            return "code_agent"

        # Check if tools are needed
        if (
            last_message
            and hasattr(last_message, "tool_calls")
            and last_message.tool_calls
        ):
            logger.info("Routing to tools")
            return "tools"

        # Otherwise, go to final responder
        return "final_responder"

    workflow.add_conditional_edges(
        "analysis_agent",
        route_from_analysis_agent,
        {
            "code_agent": "code_agent",
            "tools": "tools",
            "final_responder": "final_responder",
        },
    )

    # Knowledge agent routing
    def route_from_knowledge_agent(state: AgentState) -> str:
        """Route from knowledge agent."""
        messages = state["messages"]
        last_message = messages[-1] if messages else None

        # Check if tools are needed
        if (
            last_message
            and hasattr(last_message, "tool_calls")
            and last_message.tool_calls
        ):
            return "tools"

        return "final_responder"

    workflow.add_conditional_edges(
        "knowledge_agent",
        route_from_knowledge_agent,
        {
            "tools": "tools",
            "final_responder": "final_responder",
        },
    )

    # Confluence agent routing
    def route_from_confluence_agent(state: AgentState) -> str:
        """Route from Confluence agent."""
        messages = state["messages"]
        last_message = messages[-1] if messages else None

        # Check if tools are needed
        if (
            last_message
            and hasattr(last_message, "tool_calls")
            and last_message.tool_calls
        ):
            return "tools"

        return "final_responder"

    workflow.add_conditional_edges(
        "confluence_agent",
        route_from_confluence_agent,
        {
            "tools": "tools",
            "final_responder": "final_responder",
        },
    )

    # Code agent always routes to tool agent
    workflow.add_edge("code_agent", "tool_agent")

    # Tool agent always routes to tools
    workflow.add_edge("tool_agent", "tools")

    # Tools routing
    def route_from_tools(state: AgentState) -> str:
        """Route from tools based on context."""
        intent = state.get("intent", "ANALYSIS")
        messages = state["messages"]

        # Find the last tool message
        last_tool_message = None
        for msg in reversed(messages):
            if hasattr(msg, "name") and msg.name:
                last_tool_message = msg
                break

        # If run_analysis was called, check for errors
        if last_tool_message and hasattr(last_tool_message, "name"):
            if is_tool_name(last_tool_message.name, "run_analysis"):
                if hasattr(last_tool_message, "content"):
                    content = last_tool_message.content
                    if isinstance(content, str):
                        import json

                        try:
                            result_data = json.loads(content)
                            if isinstance(result_data, dict):
                                if result_data.get("error") or not result_data.get(
                                    "success", True
                                ):
                                    # Error - route back to analysis agent
                                    logger.info(
                                        "run_analysis failed, routing back to analysis_agent"
                                    )
                                    return "analysis_agent"
                        except (json.JSONDecodeError, TypeError):
                            pass

                # Success - route to final responder
                return "final_responder"

        # For other tools, route back to the appropriate agent
        if intent == "ANALYSIS":
            return "analysis_agent"
        elif intent == "KNOWLEDGE":
            return "knowledge_agent"
        elif intent == "CONFLUENCE":
            return "confluence_agent"
        else:
            return "final_responder"

    workflow.add_conditional_edges(
        "tools",
        route_from_tools,
        {
            "analysis_agent": "analysis_agent",
            "knowledge_agent": "knowledge_agent",
            "confluence_agent": "confluence_agent",
            "final_responder": "final_responder",
        },
    )

    # Final responder routes to verifier
    workflow.add_edge("final_responder", "verifier")

    # Verifier routing
    def route_from_verifier(state: AgentState) -> str:
        """Route from verifier based on verification result."""
        verification_result = state.get("verification_result", {})
        is_sufficient = verification_result.get("is_sufficient", True)
        intent = state.get("intent", "ANALYSIS")

        if is_sufficient:
            logger.info("Verification passed - response is sufficient")
            return "end"
        else:
            feedback = verification_result.get("feedback", "")
            logger.warning(
                f"Verification failed - response is insufficient. Feedback: {feedback}"
            )
            # Route back to the appropriate agent based on intent
            if intent == "ANALYSIS":
                return "analysis_agent"
            elif intent == "KNOWLEDGE":
                return "knowledge_agent"
            elif intent == "CONFLUENCE":
                return "confluence_agent"
            else:
                return "analysis_agent"  # Default to analysis agent

    workflow.add_conditional_edges(
        "verifier",
        route_from_verifier,
        {
            "end": END,
            "analysis_agent": "analysis_agent",
            "knowledge_agent": "knowledge_agent",
            "confluence_agent": "confluence_agent",
        },
    )

    # Compile with memory
    memory = MemorySaver()
    app = workflow.compile(checkpointer=memory)

    logger.info("Agent graph created successfully with domain-separated architecture")
    return app


# Cache for the compiled graph
_graph_cache = None


async def graph():
    """
    Entry point for LangGraph Server.

    Returns:
        Compiled LangGraph StateGraph
    """
    global _graph_cache

    if _graph_cache is None:
        _graph_cache = await create_agent()

    return _graph_cache


def get_recursion_limit() -> int:
    """Get the appropriate recursion limit based on the configured model."""
    return 50
